{"componentChunkName":"component---src-templates-blog-post-js","path":"/gradle-daemon-and-oom-in-jenkins/","result":{"data":{"site":{"siteMetadata":{"title":"Blog.kt"}},"markdownRemark":{"id":"e2a19553-98dd-5719-b4e0-a87ec483b31b","excerpt":"我们项目使用了 Jenkins 作为构建系统，用于构建提测和最终发布的安装包。最近在我升级了 JDK 版本后，那台机器构建表现一直不稳定，直接表现为： 启动后立刻失败 构建最后阶段整台机器失去响应，SSH 也无法连上，最后失败 第一种情况构建日志中可供参考的信息几乎为无： Build step ‘Invoke…","html":"<p>我们项目使用了 Jenkins 作为构建系统，用于构建提测和最终发布的安装包。最近在我升级了 JDK 版本后，那台机器构建表现一直不稳定，直接表现为：</p>\n<ol>\n<li>启动后立刻失败</li>\n<li>构建最后阶段整台机器失去响应，SSH 也无法连上，最后失败</li>\n</ol>\n<p>第一种情况构建日志中可供参考的信息几乎为无：</p>\n<blockquote>\n<p>Build step ‘Invoke Gradle script’ changed build result to FAILURE\nBuild step ‘Invoke Gradle script’ marked build as failure</p>\n</blockquote>\n<p>第二种情况会在构建开始抛出警告：</p>\n<blockquote>\n<p>Starting a Gradle Daemon, 1 busy and 6 stopped Daemons could not be reused, use —status for details</p>\n</blockquote>\n<p>根据直观表现，我猜测可能是因为 Jenkins 在构建期间 OOM 了。Jenkins 本身运行内存大概占了 30% （2.4G）左右。\n而 Daemon 的占用也不高，不过几十 MB 的程度（默认最大可到 512MB），那为啥会那么容易引发 OOM 呢？结合第二种情况的日志，我猜测是因为 daemon 进程过多导致的。</p>\n<p>要想知道 daemon 是否会过多，就得知道 daemon 创建和复用。</p>\n<h2>Gradle daemon 的复用</h2>\n<p>Gradle 利用一个持续存在的 daemon 进程来避免重复初始化导致的性能开销，可以直接地提高我们的构建速度，所以在 Gradle 3.x 版本以上就默认开启。在执行第一次构建时，Gradle 会默认启动一个 daemon 进程。</p>\n<p>但是可能因为下述不同，非常容易导致多个 daemon 进程同时存在的问题。比如：</p>\n<ul>\n<li>Gradle 版本不同，每个不同版本都需要一个相对应的 daemon</li>\n<li>Java 版本不同，启动 Gradle 的 Java 版本不同也需要重新创建一个新的 daemon</li>\n<li>JVM 参数不同，比如相同项目，但是设置了不同的内存参数（<code class=\"language-text\">-Xmx1024M</code>，这个在实际构建中可能存在）、不同的字符编码、不同的语言环境等</li>\n</ul>\n<p>对于 Android 构建来说，不同项目的 Gradle 不一致是常有的事，这非常容易导致多个 Gradle daemon 同时存在进程中。Gradle 也对此的应对方法就是，给 daemon 超时停止的机制。一旦 daemon 空闲超过 3h，那么就会被结束掉。</p>\n<p>这样来看，多 daemon 占用内存问题应该不至于导致 OOM 才对。问题出在哪呢？</p>\n<h2>JDK 升级引发 OOM？</h2>\n<p>因为问题发生始于我对 Jenkins 的运行环境升级到了 JDK11，而原本的 Gradle 构建 JDK 版本仍然是 JDK 1.8。执行第一次构建后，引发了第一次 OOM。因为问题已经解决且事故现场几乎不可逆，导致无法完全重现这个问题，目前仅能基于我的猜想：</p>\n<ol>\n<li>Jenkins 运行环境为 JDK11，Gradle 构建为 JDK 1.8，在执行 Gradle 任务时 JVM 参数（相较 JDK 1.8）有所变化，导致 daemon 不兼容。所以重新建立的 daemon 进程，继而导致 daemon 进程过多。</li>\n<li>同时运行两个 JVM，对内存造成更大压力</li>\n</ol>\n<p>在构建期间引发 OOM ，于是 Gradle 构建就失败了。</p>\n<h3>OOM 后的 daemon</h3>\n<p>当 OOM 之后，Gradle 的 daemon 可能进入异常状态，这在 <code class=\"language-text\">gradle --status</code> 中将表现为 <code class=\"language-text\">BUSY</code>。</p>\n<p>这也是 Gradle 构建时提示 <code class=\"language-text\">1 busy and 6 stopped Daemons could not be reused</code> 的原因。可能是在我切换 JVM 导致 OOM 之后，所有已存在的 Gradle daemon 都进入异常（Lock）状态，加上后续不断重新构建，daemon 数量有增无减，导致内存占用居高不下，而频繁 OOM?</p>\n<h2>解决方法</h2>\n<p>每个 daemon 运行后，会在 <code class=\"language-text\">/var/lib/Jenkins/.gradle/daemon</code> 中写入注册表和 log 文件，我在机器中看到这个文件夹中一共有多个 Gradle 版本，包括异常状态的 daemon 版本，他们将不会被 Gradle 默认的清除策略所清除。</p>\n<p>在我直接删除 <code class=\"language-text\">.gradle/daemon</code> 下的所有版本，重新开启构建即可。经过多日测试，发现再无 OOM 的情况发生。</p>\n<h2>2021/08/10 更新</h2>\n<p>一段时间后该 OOM 还是 OOM，考虑可能是 Gradle 版本升级后对内存占用提升了。建议升级机器… >_&#x3C;</p>\n<hr>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/32133013/java-lang-outofmemoryerror-gc-overhead-limit-exceeded-on-android-1-4\">java.lang.OutOfMemoryError: GC overhead limit exceeded on Android 1.4</a></li>\n<li><a href=\"https://stackoverflow.com/a/58195352/7293728\">Starting a Gradle Daemon, 1 busy and 6 stopped Daemons could not be reused, use —status for details</a></li>\n<li><a href=\"https://docs.gradle.org/5.5/userguide/gradle_daemon.html\">The Gradle Daemon</a></li>\n<li><a href=\"https://docs.gradle.org/current/userguide/directory_layout.html\">The Directories and Files Gradle Uses</a></li>\n</ul>","frontmatter":{"title":"Gradle daemon 与 OOM","date":"2021-07-23","description":null,"excerpt":null}},"previous":{"fields":{"slug":"2021-05-26-av-basic-pcm-samplerate-bit-depth-and-bitrate-and-more"},"frontmatter":{"title":"音视频基础概念：PCM、采样率、位深和比特率"}},"next":{"fields":{"slug":"intro-sparsearray"},"frontmatter":{"title":"SparseArray 简介"}}},"pageContext":{"id":"e2a19553-98dd-5719-b4e0-a87ec483b31b","previousPostId":"db50fc59-6152-5eb2-8f10-9daa5d4661d3","nextPostId":"08ed1263-759b-5215-b528-844e800d39bc"}},"staticQueryHashes":["2082311839","2355076697","959449634"],"slicesMap":{}}